{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we compare two CNN's - a CIFAR10 \"simple deep CNN\" and an identical CNN that was trained on a version of CIFAR10 that had been attacked with untargeted FGSM. The FGSM was done using an EfficientNet.\n",
    "\n",
    "First, we see the effect of the adversarial images on the regular CNN vs the adversarially trained CNN.\n",
    "\n",
    "Next, we evalute the effectiveness of gaussian filtering as a defense against the adversarial images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from scipy import ndimage\n",
    "import random\n",
    "import helper\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 120\n",
    "data_augmentation = False\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the regular CIFAR10 CNN\n",
    "\n",
    "model_name = 'keras_cifar10_trained_model_1.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "model = load_model(os.path.join(save_dir, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the adversarially trained CIFAR10 CNN\n",
    "\n",
    "model_adv_name = 'keras_cifar10_adversarial_trained_model.h5'\n",
    "\n",
    "x_train_adv = np.load('./data/x_train_adversarial.npy')\n",
    "y_train_adv = np.load('./data/y_train_adversarial.npy')\n",
    "x_test_adv = np.load('./data/x_test_adversarial.npy')\n",
    "y_test_adv = np.load('./data/y_test_adversarial.npy')\n",
    "\n",
    "model_adv = load_model(os.path.join(save_dir, model_adv_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'helper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-33e9a7e583e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_adv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'helper' is not defined"
     ]
    }
   ],
   "source": [
    "# showing some examples of original vs adversarial images classified by the regular CIFAR10 CNN\n",
    "\n",
    "for i in range(10):\n",
    "    idx = random.randint(0,50000)\n",
    "    helper.plot_image((x_train[idx] * 255).astype('int'))\n",
    "    helper.plot_image((x_train_adv[idx]*255).astype('int'))\n",
    "    predictions = model.predict(np.tile(x_train[idx],[1,1,1,1]))\n",
    "    print(\"prediction: %s\" % (classes[predictions.argmax()]))\n",
    "    print(\"confidence: %f\" % (predictions.max()))\n",
    "\n",
    "\n",
    "    predictions = model.predict(np.tile(x_train_adv[idx],[1,1,1,1]))\n",
    "    print(\"prediction (adversarial): %s\" % (classes[predictions.argmax()]))\n",
    "    print(\"confidence: %f\" % (predictions.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial testing shows that the adversarial images decrease the confidence of the classification, and only misclassify a few images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantifying results\n",
    "\n",
    "print(\"CNN score on test set:\")\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "print(\"\\nCNN score on adversarial test set:\")\n",
    "scores = model.evaluate(x_test_adv, y_test_adv, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "print(\"\\nAdversarially trained CNN score on test set:\")\n",
    "scores = model_adv.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "print(\"\\nAdversarially trained CNN score on adversarial test set:\")\n",
    "scores = model_adv.evaluate(x_test_adv, y_test_adv, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that adversarial training is somewhat successful at defending against the adversarial images. Interestingly, the adversarially trained model did better on both test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing cases where the adversarial image failed to missclassify vs cases where it succeded\n",
    "\n",
    "adv_succ_conf = list()\n",
    "adv_fail_conf = list()\n",
    "for i in range(10000):\n",
    "    predictions = model.predict(np.tile(x_test[i],[1,1,1,1]))\n",
    "    chosen = predictions.argmax()\n",
    "    adv_predictions = model.predict(np.tile(x_test_adv[i],[1,1,1,1]))\n",
    "    chosen_adv = adv_predictions.argmax()\n",
    "    if chosen == chosen_adv: adv_fail_conf.append(predictions.max())\n",
    "    else: adv_succ_conf.append(adv_predictions.max())\n",
    "        \n",
    "adv_succ_conf = np.asarray(adv_succ_conf, dtype=np.float32)\n",
    "adv_fail_conf = np.asarray(adv_fail_conf, dtype=np.float32)\n",
    "\n",
    "print(\"Average confidence of original classification where adversarial image failed: %f\" % adv_fail_conf.mean())\n",
    "print(\"Average confidence of original classification where adversarial image succeeded: %f\" % adv_succ_conf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the adversarial image is more likely to miscalssify if the original confidence was low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing the effect of gaussian filtering at different std values on an example image\n",
    "\n",
    "idx = 335\n",
    "plt.imshow(x_test[idx])\n",
    "plt.show()\n",
    "predictions = model.predict(np.tile(x_test[idx],[1,1,1,1]))\n",
    "print(\"Predicted class %s with confidence %f\" % (classes[predictions.argmax()], predictions.max()))\n",
    "\n",
    "t0 = time.time()\n",
    "sig6 = ndimage.gaussian_filter(x_test[idx], sigma=.6)\n",
    "t1 = time.time()\n",
    "print(\"delta t: %f\" % (t1-t0))\n",
    "plt.imshow(sig6)\n",
    "plt.show()\n",
    "predictions = model.predict(np.tile(sig6,[1,1,1,1]))\n",
    "print(\"Predicted class %s with confidence %f\" % (classes[predictions.argmax()], predictions.max()))\n",
    "\n",
    "sig8 = ndimage.gaussian_filter(x_test[idx], sigma=.8)\n",
    "plt.imshow(sig8)\n",
    "plt.show()\n",
    "predictions = model.predict(np.tile(sig8,[1,1,1,1]))\n",
    "print(\"Predicted class %s with confidence %f\" % (classes[predictions.argmax()], predictions.max()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying gaussian filtering at various std values to the CIFAR10 test set and the adversarial CIFAR10 test set\n",
    "\n",
    "x_test_adv_filtered = np.zeros([7, 10000, 32, 32, 3])\n",
    "x_test_filtered = np.zeros([7, 10000, 32, 32, 3])\n",
    "\n",
    "for i in range(10000):\n",
    "    x_test_adv_filtered[0][i] = ndimage.gaussian_filter(x_test_adv[i], sigma=.2)\n",
    "    x_test_filtered[0][i] = ndimage.gaussian_filter(x_test[i], sigma=.2)\n",
    "    \n",
    "    x_test_adv_filtered[1][i] = ndimage.gaussian_filter(x_test_adv[i], sigma=.3)\n",
    "    x_test_filtered[1][i] = ndimage.gaussian_filter(x_test[i], sigma=.3)\n",
    "    \n",
    "    x_test_adv_filtered[2][i] = ndimage.gaussian_filter(x_test_adv[i], sigma=.4)\n",
    "    x_test_filtered[2][i] = ndimage.gaussian_filter(x_test[i], sigma=.4)\n",
    "    \n",
    "    x_test_adv_filtered[3][i] = ndimage.gaussian_filter(x_test_adv[i], sigma=.5)\n",
    "    x_test_filtered[3][i] = ndimage.gaussian_filter(x_test[i], sigma=.5)\n",
    "    \n",
    "    x_test_adv_filtered[4][i] = ndimage.gaussian_filter(x_test_adv[i], sigma=.6)\n",
    "    x_test_filtered[4][i] = ndimage.gaussian_filter(x_test[i], sigma=.6)\n",
    "    \n",
    "    x_test_adv_filtered[5][i] = ndimage.gaussian_filter(x_test_adv[i], sigma=.7)\n",
    "    x_test_filtered[5][i] = ndimage.gaussian_filter(x_test[i], sigma=.7)\n",
    "    \n",
    "    x_test_adv_filtered[6][i] = ndimage.gaussian_filter(x_test_adv[i], sigma=.8)\n",
    "    x_test_filtered[6][i] = ndimage.gaussian_filter(x_test[i], sigma=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# testing filtered test set and filtered adversarial test set on both the regular and adversarially trained CNN's\n",
    "\n",
    "for i in range(7):\n",
    "    print(\"\\nUnaltered+filtered test set evaluation\")\n",
    "    scores = model.evaluate(x_test_filtered[i], y_test, verbose=1)\n",
    "    scores_adv = model_adv.evaluate(x_test_filtered[i], y_test, verbose=1)\n",
    "    print('Original model test accuracy:', scores[1])\n",
    "    print('Retrained model test accuracy:', scores_adv[1])\n",
    "    print('Original model test loss:', scores[0])\n",
    "    print('Retrained model test loss:', scores_adv[0])\n",
    "\n",
    "for i in range(7):\n",
    "    print(\"\\nAdversarial+filtered test set evaluation\")\n",
    "    scores = model.evaluate(x_test_adv_filtered[i], y_test_adv, verbose=1)\n",
    "    scores_adv = model_adv.evaluate(x_test_adv_filtered[i], y_test_adv, verbose=1)\n",
    "    print('Original model test accuracy:', scores[1])\n",
    "    print('Retrained model test accuracy:', scores_adv[1])\n",
    "    print('Original model test loss:', scores[0])\n",
    "    print('Retrained model test loss:', scores_adv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
